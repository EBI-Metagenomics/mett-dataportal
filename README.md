# ME TT Data Portal

The transversal theme aims at mechanistically understanding the complex role that human-associated microbiomes play in
human health and disease. Our current knowledge of bacterial gene functions come primarily from very few model bacteria,
failing to capture the genetic diversity within the gut microbiome. One of the goals of METT is to systematically tackle
the vast genetic matter in the gut microbiome and two establish new model microbes. The Flagship Project of METT has
focused efforts on annotating the genomes of Phocaeicola Vulgatus and Bacteroides uniformis, two of the most prevalent
and abundant bacterial species of the human microbiome.

The current version is a web-based genomic annotation editing platform designed to browse the genomes of the type
strains B. uniformis (ATCC8492) and P. vulgatus (ATCC8482). The annotation data generated by the ME TT has been
organised on an FTP directory hosted at EBI and contains structural annotations (such as Prokka and Mobilome
predictions, etc.) as well as functional annotations (including biosynthetic gene clusters, carbohydrate active enzymes,
etc.) .

## Data Portal API

### Requirements

- **Python Version**: This project requires **Python 3.13**. Please ensure that you have this version installed to avoid
  compatibility issues.
- You can download the latest version [here](https://www.python.org/downloads/).

### Development Environment

#### Dependencies installation -

```shell
$ uv pip compile pyproject.toml --group dev --generate-hashes > uv.lock
$ uv pip install -r uv.lock
$ uv pip install -r uv.lock  --no-dev (for production)
$ pre-commit install
```

#### Local Docker container 
```shell
$ docker build -t mett-dataportal:dev-test -f dataportal_api/Dockerfile .
$ docker run --rm -it -p 8000:8000 mett-dataportal:dev
```

### Steps to bring up the local environment

- [X] Migration files are in repo. use ```python manage.py migrate``` to setup the tables
- [X] Use import scripts to import the data from FTP server.
  Ref: [How to import](data-generators/import-scripts/README.md)
- [X] Create indexes for Fasta and GFF files.
  Ref: [How to generate indexes](data-generators/index-scripts/README.md)
- [X] Run djando sever ```python manage.py runserver```
- [X] Run react **./dataportal-app** app using ```npm start```

### Configuration

We use [Pydantic](https://pydantic-docs.helpmanual.io/) to formalise Config files.

- `config/local.env` as a convenience for env vars.

### Import Species, Strains and Annotations

#### Elasticsearch Database setup
```shell
$ python manage.py create_es_index
$ python manage.py create_es_indexes --es-version 2025.09.03
$ python manage.py create_es_indexes --es-version 2025.09.03 --if-exists recreate
```
### Import data

#### Species
```shell
$ python manage.py import_strains \
  --es-index strain_index-2025.09.03 \
  --map-tsv ../data-generators/data/gff-assembly-prefixes.tsv \
  --ftp-server ftp.ebi.ac.uk \
  --ftp-directory /pub/databases/mett/all_hd_isolates/deduplicated_assemblies/ \
  --set-type-strains BU_ATCC8492 PV_ATCC8482
```

#### Strains
Strains + contigs only:
```shell
$ python manage.py import_strains \
  --es-index strain_index-2025.09.05 \
  --map-tsv ../data-generators/data/gff-assembly-prefixes.tsv \
  --ftp-server ftp.ebi.ac.uk \
  --ftp-directory /pub/databases/mett/all_hd_isolates/deduplicated_assemblies/ \
  --set-type-strains BU_ATCC8492 PV_ATCC8482
```
Strains - All in one go: 
```shell
$ python manage.py import_strains \
  --es-index strain_index-2025.09.05 \
  --map-tsv ../data-generators/data/gff-assembly-prefixes.tsv \
  --ftp-server ftp.ebi.ac.uk \
  --ftp-directory /pub/databases/mett/all_hd_isolates/deduplicated_assemblies/ \
  --set-type-strains BU_ATCC8492 PV_ATCC8482 \
  --include-mic \
  --mic-bu-file /Users/vikasg/Documents/METT/Sub-Projects-Data/SP5/BU_growth_inhibition.csv \
  --mic-pv-file /Users/vikasg/Documents/METT/Sub-Projects-Data/SP5/PV_growth_inhibition.csv \
  --include-metabolism \
  --metab-bu-file /Users/vikasg/Documents/METT/Sub-Projects-Data/SP5/SP5_drug_metabolism_BU_v0.csv \
  --metab-pv-file /Users/vikasg/Documents/METT/Sub-Projects-Data/SP5/SP5_drug_metabolism_PV_v0.csv \
  --gff-server ftp.ebi.ac.uk \
  --gff-base /pub/databases/mett/annotations/v1_2024-04-15/
```
Add Drug MIC:
```shell
$ python manage.py import_strains \
  --es-index strain_index-2025.09.04 \
  --skip-strains \
  --include-mic \
  --mic-bu-file /Users/vikasg/Documents/METT/Sub-Projects-Data/SP5/BU_growth_inhibition.csv \
  --mic-pv-file /Users/vikasg/Documents/METT/Sub-Projects-Data/SP5/PV_growth_inhibition.csv
```
Add Drug Metabolism:
```shell
$ python manage.py import_strains \
  --es-index strain_index-2025.09.04 \
  --skip-strains \
  --include-metabolism \
  --metab-bu-file /Users/vikasg/Documents/METT/Sub-Projects-Data/SP5/SP5_drug_metabolism_BU_v0.csv \
  --metab-pv-file /Users/vikasg/Documents/METT/Sub-Projects-Data/SP5/SP5_drug_metabolism_PV_v0.csv

```

#### Features
Basic Genes from GFF and Essentiality:
```shell
$ python manage.py import_features \
  --index feature_index-2026.09.06 \
  --mapping-task-file ../data-generators/data/gff-assembly-prefixes.tsv


```
Process Everything in one go:
```shell
$ python manage.py import_features \
  --index feature_index \
  --ftp-server ftp.ebi.ac.uk \
  --ftp-root /pub/databases/mett/annotations/v1_2024-04-15 \
  --mapping-task-file ../data-generators/data/gff-assembly-prefixes.tsv \
  --essentiality-dir ../data-generators/Sub-Projects-Data/SP1/ \
  --proteomics-dir ../data-generators/Sub-Projects-Data/proteomics_evidence/ \
  --gene-rx-dir ../data-generators/Sub-Projects-Data/SP3/GEMs/gene_rx/ \
  --met-rx-dir ../data-generators/Sub-Projects-Data/SP3/GEMs/met_rx/ \
  --rx-gpr-dir ../data-generators/Sub-Projects-Data/SP3/GEMs/gpr/ \
  --protein-compound-dir ../data/protein_compound/ \
  --mutant-growth-dir ../data/mutant_growth/ \
  --fitness-dir ../data/fitness/ \
```

Essentiality:
```shell
$ python manage.py import_features \
  --index feature_index \
  --ftp-server ftp.ebi.ac.uk \
  --ftp-root /pub/databases/mett/annotations/v1_2024-04-15 \
  --skip-core-genes \
  --essentiality-dir ../data-generators/Sub-Projects-Data/SP1/
```

Proteomics Evidence:
```shell
$ python manage.py import_features \
  --index feature_index \
  --ftp-server ftp.ebi.ac.uk \
  --ftp-root /pub/databases/mett/annotations/v1_2024-04-15 \
  --skip-core-genes \
  --proteomics-dir ../data-generators/Sub-Projects-Data/proteomics_evidence/
```


Gene Rx Data:
```shell
$ python manage.py import_features \
  --index feature_index \
  --ftp-server ftp.ebi.ac.uk \
  --ftp-root /pub/databases/mett/annotations/v1_2024-04-15 \
  --skip-core-genes \
  --gene-rx-dir ../data-generators/Sub-Projects-Data/SP3/GEMs/gene_rx/ \
  --met-rx-dir ../data-generators/Sub-Projects-Data/SP3/GEMs/met_rx/ \
  --rx-gpr-dir ../data-generators/Sub-Projects-Data/SP3/GEMs/gpr/
```

#### Protein Protein Index (PPI):
```shell
$ python manage.py import_ppi --index ppi_index --pattern "*.csv" --dir ../data-generators/Sub-Projects-Data/SP2/  
$ python manage.py import_ppi --index ppi_index --pattern "*.csv" --dir ../data-generators/Sub-Projects-Data/SP2/ --refresh-every-rows 500000   # or --refresh-every-secs 120
```



#### Pyhmmer Database Migrations
```shell
$ python manage.py migrate pyhmmer_search
```


#### Celery Beat Migrations
```shell
$ python manage.py migrate django_celery_beat
```


#### Code style

Use [Black](https://black.readthedocs.io/en/stable/).
Use [Ruff](https://docs.astral.sh/ruff/installation/).
These are both configured if you install the pre-commit tools as above.

To manually run them:
`black .` and `ruff check --fix`.

#### Testing

```shell
$ uv lock
$ pytest

# Run all service tests
pytest dataportal/tests/services/ -v

# Run with coverage
pytest dataportal/tests/services/ --cov=dataportal.services --cov-report=html
```

### Kubernetes Node Affinity 
```bash
$ kubectl label node hh-rke-wp-webadmin-52-worker-1.caas.ebi.ac.uk mett-pyhmmer-data=true
$ kubectl get nodes -l mett-pyhmmer-data=true
```
